/**
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * Copyright (c) 2013 by Delphix. All rights reserved.
 */

package com.delphix.session.util;

import java.io.IOException;
import java.io.OutputStream;

/**
 * LZ4 based output stream that compresses data by splitting it into variable length chunks and compressing each
 * chunk individually. The wire encoding for a LZ4 compressed data stream assumes the following format.
 *
 *              chunk = <compressed data length> + <compressed data>
 *             stream = chunk*
 *
 * where minSize <= <uncompressed data length> <= maxSize. minSize and maxSize are specified when a new output
 * stream is created. If less than minSize data is written at a time, the data will be staged until either minSize
 * is exceeded or the stream is flushed. Otherwise, the input is compressed directly (without an additional copy)
 * and the result written to the output stream. Compression ratio could be affected adversely using small maxSize
 * and minSize because the limited compression space. OTOH, larger values may lead to unnecessary data copies.
 *
 * The <compressed data> is generated by the LZ4 codec in use with the output stream. It takes an encoding form of
 * the raw LZ4 compressor output. For example, with the use of LZ4LengthCodec, it will assume the following format.
 *
 *  <compressed data> = <uncompressed data length> + <lz4 compressor output>
 *
 * Both the <compressed data length> and <uncompressed data length> fields are four byte in length.
 */
public class LZ4OutputStream extends OutputStream {

    private static final int DEFAULT_BUFFER_MIN = 4096;
    private static final int DEFAULT_BUFFER_MAX = 65536;

    private final OutputStream os;

    private final LZ4Codec codec;

    private final int minUncompressedLength;
    private final int maxUncompressedLength;
    private final int maxCompressedLength;

    // Staging buffer for data chunk accumulation
    private final byte[] stagingBuffer;
    private int stagingOffset;

    // Encoded buffer with compressed data
    private final byte[] encodedBuffer;

    /**
     * Create a new OutputStream. The maxSize and minSize specify the maximum and minimum sizes of the chunk to be
     * compressed, respectively.
     */
    public LZ4OutputStream(OutputStream os, LZ4Codec codec, int minSize, int maxSize) {
        if (minSize < 1) {
            throw new IllegalArgumentException("invalid minSize - must be > 0");
        }

        if (maxSize < 1) {
            throw new IllegalArgumentException("invalid maxSize - must be > 0");
        }

        if (minSize > maxSize) {
            throw new IllegalArgumentException("invalid min/maxSize - minSize must be <= maxSize");
        }

        this.os = os;
        this.codec = codec;

        this.minUncompressedLength = minSize;
        this.maxUncompressedLength = maxSize;
        this.maxCompressedLength = codec.getMaxCompressedLength(maxSize);

        this.stagingBuffer = new byte[minUncompressedLength];
        this.encodedBuffer = new byte[maxCompressedLength + 4];
    }

    public LZ4OutputStream(OutputStream os, LZ4Codec codec, int maxSize) {
        this(os, codec, maxSize > 1 ? maxSize / 2 : maxSize, maxSize);
    }

    public LZ4OutputStream(OutputStream os, LZ4Codec codec) {
        this(os, codec, DEFAULT_BUFFER_MIN, DEFAULT_BUFFER_MAX);
    }

    /**
     * For variable length chunk compression, the maximum compressed length depends on how the data is written.
     * The following calculation assumes the worst case scenario where compression is done over the minimum chunk
     * size.
     */
    public static int getMaxCompressedLength(int len, int minSize, LZ4Codec codec) {
        int minChunks = len / minSize;
        int remainder = len % minSize;

        int length = minChunks * (codec.getMaxCompressedLength(minSize) + 4);

        if (remainder > 0) {
            length += codec.getMaxCompressedLength(remainder) + 4;
        }

        return length;
    }

    public int getMinUncompressedLength() {
        return minUncompressedLength;
    }

    public int getMaxUncompressedLength() {
        return maxUncompressedLength;
    }

    @Override
    public void write(int b) throws IOException {
        ensureOpen();

        stagingBuffer[stagingOffset++] = (byte) b;

        if (stagingOffset == stagingBuffer.length) {
            encode();
        }
    }

    @Override
    public void write(byte[] buf, int off, int len) throws IOException {
        ensureOpen();

        // Check if there is enough data (staging and incoming combined) to compress a chunk
        if (stagingOffset + len >= minUncompressedLength) {
            // Pick up from where we left in the staging buffer
            if (stagingOffset > 0) {
                int copied = stagingBuffer.length - stagingOffset;
                assert copied > 0;

                System.arraycopy(buf, off, stagingBuffer, stagingOffset, copied);

                off += copied;
                len -= copied;

                stagingOffset = stagingBuffer.length;
                encode();
            }

            // Compress the rest of the data
            while (len >= minUncompressedLength) {
                int size = Math.min(len, maxUncompressedLength);

                encodeFrom(buf, off, size);

                off += size;
                len -= size;
            }
        }

        // Copy the remaining data to the staging buffer
        if (len > 0) {
            System.arraycopy(buf, off, stagingBuffer, stagingOffset, len);
            stagingOffset += len;
        }
    }

    private void encodeFrom(byte[] buf, int off, int len) throws IOException {
        ensureOpen();

        if (buf != stagingBuffer && stagingOffset != 0) {
            throw new IllegalStateException();
        }

        if (len > 0) {
            int compressedLen = codec.compress(buf, off, len, encodedBuffer, 4, maxCompressedLength);

            // Encode the compressed data length prior to the compressed data chunk
            encodedBuffer[0] = (byte) (compressedLen >>> 24);
            encodedBuffer[1] = (byte) (compressedLen >>> 16);
            encodedBuffer[2] = (byte) (compressedLen >>> 8);
            encodedBuffer[3] = (byte) compressedLen;

            os.write(encodedBuffer, 0, 4 + compressedLen);
        }
    }

    private void encode() throws IOException {
        encodeFrom(stagingBuffer, 0, stagingOffset);
        stagingOffset = 0;
    }

    @Override
    public void flush() throws IOException {
        encode();
        os.flush();
    }

    @Override
    public void close() throws IOException {
        ensureOpen();

        try {
            flush();
        } finally {
            stagingOffset = -1;

            super.close();
            os.close();
        }
    }

    private void ensureOpen() throws IOException {
        if (stagingOffset == -1) {
            throw new IOException("This outputstream is already closed");
        }
    }
}
